### Домашнее задание ###

**Цель:** - уметь развернуть multi master кластер PostgreSQL своими руками  
- уметь развернуть PostgreSQL like географически распределенный сервис от одного из 3-х крупнейших облачных провайдеров - AWS, GCP и Azure  
1 вариант:  
Развернуть CockroachDB в GKE или GCE  
Потесировать dataset с чикагскими такси  
Или залить 10Гб данных и протестировать скорость запросов в сравнении с 1 инстансом PostgreSQL  
Описать что и как делали и с какими проблемами столкнулись  
2 вариант:  
Переносим тестовую БД 10 Гб в географически распределенный PostgeSQL like сервис   


ставим управление кластером на виртуальную же машину в гуге :   

Настраиваем окружение для работы с GKE :   

https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/  

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"  

sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl  

echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list  

sudo apt-get install apt-transport-https ca-certificates gnupg  

curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring   /usr/share/keyrings/cloud.google.gpg add -  

sudo apt-get update && sudo apt-get install google-cloud-sdk  

gcloud init  
выбрать вариант - новый аккаунт. пройти с логином через браузер. там получить ключ для работы из виртуалки   


gcloud beta container --project "tensile-analyst-305614" clusters create "testcluster4" --zone "us-central1-c" --no-enable-basic-auth --cluster-version "1.17.17-gke.1101" --release-channel "None" --machine-type "e2-medium" --image-type "COS" --disk-type "pd-standard" --disk-size "200" --metadata disable-legacy-endpoints=true --scopes "https://www.googleapis.com/auth/devstorage.read_only","https://www.googleapis.com/auth/logging.write","https://www.googleapis.com/auth/monitoring","https://www.googleapis.com/auth/servicecontrol","https://www.googleapis.com/auth/service.management.readonly","https://www.googleapis.com/auth/trace.append" --num-nodes "4" --enable-stackdriver-kubernetes --enable-ip-alias --network "projects/tensile-analyst-305614/global/networks/default" --subnetwork "projects/tensile-analyst-305614/regions/us-central1/subnetworks/default" --default-max-pods-per-node "110" --no-enable-master-authorized-networks --addons HorizontalPodAutoscaling,HttpLoadBalancing --enable-autoupgrade --enable-autorepair --max-surge-upgrade 1 --max-unavailable-upgrade 0 --node-locations "us-central1-c"  


конфигурим kubectl   
https://cloud.google.com/kubernetes-engine/docs/how-to/api-server-authentication?hl=ru  


gcloud container clusters describe testcluster4 \  
    --zone=us-central1-c \  
     --format="value(endpoint)"  
     
gcloud container clusters describe testcluster4 \  
    --zone=us-central1-c \  
    --format="value(masterAuth.clusterCaCertificate)"  
    
**./kubeconfig.yaml**  
    
```    
apiVersion: v1
kind: Config
clusters:
- name: testcluster4
  cluster:
    server: https://35.226.166.195
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURLekNDQWhPZ0F3SUJBZ0lSQUxGTlo3cTR4OFVSb2VvVmZ3TFpRV3d3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa05qY3hOREkzTlRjdE1HVmpaUzAwTURaa0xXSTBZell0TW1aa1lXVXhObUU1WldVMQpNQjRYRFRJeE1ETXhNakE0TlRFMU5sb1hEVEkyTURNeE1UQTVOVEUxTmxvd0x6RXRNQ3NHQTFVRUF4TWtOamN4Ck5ESTNOVGN0TUdWalpTMDBNRFprTFdJMFl6WXRNbVprWVdVeE5tRTVaV1UxTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBcC9hNGo5YjNhaERidG1NUUs3cStycGZTL1BkTjVEcTRoSlBYc3pIegpoSEpERTRpdmx3UnJTbVBIQkdka2ovTnFycTdaZ1prL2c4TkVYRUJ4czZjL3JidlY4YXhQd1N6RndkL09RdElQCkJRMG01ZitneWpTVXpsMi9abWRJVGl6MjhaWkxDeFNtcTdKaitCdVA2U0Q5VkNMV3ZWVHZheHZuSjdBUDE0N2gKOTFNUWJpdmJVUkluS2llbWZMN3NDdzMzdDEyU0pBeFZ3bXRZYWhFTHdHWmllalljdzgyZThnSWhnWHNIdW9uNAprZjBackVFd3A2Zm80YXlycGE2TTNlM2dlZTlqOW1FMXdxZjA2NUlndG1HbG5RZFU4Sm1INDN3cHBYbTcvWWRmCnNzQWdVYUdKZ3FuenU0SkpzcHEvc0dlSExVV1JWUlNIQ2Y4RUYxdWVMeDhtRlFJREFRQUJvMEl3UURBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVURBUWFFVnNVV3crUApPditVMFdKYUF0ZDVpTGd3RFFZSktvWklodmNOQVFFTEJRQURnZ0VCQUVwankxS2xVYWtZWVMvREdHK3BjdExqClNqSkYyeVY0TThOdmpDaTFOSXF2dmtEWnJxc01STHRwbThpL09FaFg4VENZTTJXdzFMTng3cy9MV09jRm9zMk8KWUhpYTRrMFVVdjdVS3MrQjNYWVNuMVFpSmNucjNna1JpK2Jmenl1ZzcvV1pORldOZ1Z1ckNLL1hzT0tFOGwrcwptWlNoNXpFWFJkcUZTQ1p0NFhKdUhneDA4eXZDMk8vd3llZU9VVWtNVkJQOFJJeC9wL0tDR2tRM0c2dVdJV09VCnl5OXdVR3V3czJCZUhINWhsbHYrWWdiM0NONEhzM3NEZm05VHNldEdnZFBmUlNURzBvS2J2VC9kaGEvUE1GSHgKaVJuNzB4dXI4ZkJvZVJlN2t4allMUDViU0tYVDVZVmZXUXVTUkNmUnl3akE5YWxldDUyaHoxd0IrUXdzeDJvPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
users:
- name: ci-cd-pipeline-gsa
  user:
    auth-provider:
      name: gcp
contexts:
- context:
    cluster: testcluster4
    user: ci-cd-pipeline-gsa
  name: testcluster4-ci-cd
current-context: testcluster4-ci-cd  
```    

export KUBECONFIG=/tmp/kubeconfig.yaml  

gcloud iam service-accounts keys create gsa-key.json \  
    --iam-account=540654827891-compute@developer.gserviceaccount.com   

export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gsa-key.json  

```
kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.32.0.1    <none>        443/TCP   97m
```

**ставим HELM**    
https://helm.sh/docs/intro/install/   

curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -  
sudo apt-get install apt-transport-https --yes  
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list  
sudo apt-get update  
sudo apt-get install helm  

Git :   
 apt-get install git  
 
 git clone https://github.com/cockroachdb/helm-charts  
cd helm-charts/cockroachdb  

helm repo add cockroachdb https://charts.cockroachdb.com/  
helm repo update  

helm install cockroach . --values my-values.yaml    

_(команда удаления :  helm ls --all --short | xargs -L1 helm delete )_  

  
kubectl get all  

```
kubectl get all
NAME                                   READY   STATUS      RESTARTS   AGE
pod/cockroach-cockroachdb-0            1/1     Running     0          61m
pod/cockroach-cockroachdb-1            1/1     Running     0          61m
pod/cockroach-cockroachdb-2            1/1     Running     0          61m
pod/cockroach-cockroachdb-init-qmdsh   0/1     Completed   0          61m

NAME                                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)              AGE
service/cockroach-cockroachdb          ClusterIP   None          <none>        26257/TCP,8080/TCP   61m
service/cockroach-cockroachdb-public   ClusterIP   10.32.9.169   <none>        26257/TCP,8080/TCP   61m
service/kubernetes                     ClusterIP   10.32.0.1     <none>        443/TCP              161m

NAME                                     READY   AGE
statefulset.apps/cockroach-cockroachdb   3/3     61m

NAME                                   COMPLETIONS   DURATION   AGE
job.batch/cockroach-cockroachdb-init   1/1           29s        61m
```
kubectl get pv  

```
kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                     STORAGECLASS   REASON   AGE
pvc-3419ec27-4aac-4768-b223-417000cc1b7d   100Gi      RWO            Delete           Bound    default/datadir-cockroach-cockroachdb-2   standard                61m
pvc-8ad10525-478e-4dd5-a6a2-1fe7fef9e15c   100Gi      RWO            Delete           Bound    default/datadir-cockroach-cockroachdb-1   standard                61m
pvc-c749fd13-68ca-4bb8-91ea-6739c30f60a8   100Gi      RWO            Delete           Bound    default/datadir-cockroach-cockroachdb-0   standard                61m
```
kubectl run cockroachdb -it --image=cockroachdb/cockroach:v20.2.4 --rm --restart=Never -- sql --insecure --host=cockroach-cockroachdb-public  

```
kubectl run cockroachdb -it --image=cockroachdb/cockroach:v20.2.4 --rm --restart=Never -- sql --insecure --host=cockroach-cockroachdb-public  
If you don't see a command prompt, try pressing enter.  
root@cockroach-cockroachdb-public:26257/defaultdb>   
root@cockroach-cockroachdb-public:26257/defaultdb>   
```
выгрузка такси одним файлом не дает гугл.   
немного ошибся инструкцией в итоге выгрузил   
пару сотен файлов в формате :  
 gs://cikagotaxi/taxitest/tbltaxi-<worker number>-000000000000.csv     
gs://cikagotaxi/taxitest/tbltaxi-<worker number>-000000000001.csv   
...  
gs://cikagotaxi/taxitest/tbltaxi-<worker number>-000000000xxxx.csv  
  
пробуем загружать :   

```
create table taxi_trips(
unique_key	STRING	,
taxi_id	STRING	,
trip_start_timestamp	STRING	,
trip_end_timestamp	STRING	,
trip_seconds	STRING	,
trip_miles	STRING	,
pickup_census_tract	STRING	,
dropoff_census_tract	STRING	,
pickup_community_area	STRING	,
dropoff_community_area	STRING	,
fare	STRING	,
tips	STRING	,
tolls	STRING	,
extras	STRING	,
trip_total	STRING	,
payment_type	STRING	,
company	STRING	,
pickup_latitude	STRING	,
pickup_longitude	STRING	,
pickup_location	STRING	,
dropoff_latitude	STRING	,
dropoff_longitude	STRING	,
dropoff_location	STRING	
);

import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/tbltaxi-<worker number>-000000000000.csv') WITH DELIMITER = ',', SKIP = '1';
        job_id       |  status   | fraction_completed |  rows  | index_entries |   bytes
---------------------+-----------+--------------------+--------+---------------+------------
  640370902961192962 | succeeded |                  1 | 669384 |             0 | 294816924
(1 row)

Time: 19.299s total (execution 19.299s / network 0.001s)


root@cockroach-cockroachdb-public:26257/taxi> import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/tbltaxi-<worker number>-000000000001.csv') WITH DELIMITER = ',', SKIP = '1';
        job_id       |  status   | fraction_completed |  rows  | index_entries |   bytes
---------------------+-----------+--------------------+--------+---------------+------------
  640372007409090562 | succeeded |                  1 | 654725 |             0 | 293058348
(1 row)

Time: 27.487s total (execution 27.484s / network 0.002s)


```
руками команды запускать для каждого файла скучно ...   
нашел тут :     

https://www.cockroachlabs.com/docs/v20.1/cockroach-sql.html    

как это делать в цикле.   

\| for ((i=10;i<99;++i)); do echo "import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/tbltaxi-<worker number>-0000000000$i.csv') WITH DELIMITER = ',', SKIP = '1';"; done   


```
root@cockroach-cockroachdb-public:26257/taxi> \| for ((i=10;i<99;++i)); do echo "import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/tbltaxi-<worker number>-0000000000$i.csv') WITH DELIMITER = ',', SKIP = '1';"; done

select count(*) from taxi_trips;
   count
------------
  11747943
(1 row)
Time: 29.984s total (execution 29.983s / network 0.002s)

```

эту не стал делать т.к. в прошлый раз кластер переполнился и умер :   

> root@cockroach-cockroachdb-public:26257/taxi>\| for ((i=100;i<299;++i)); do echo "import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/tbltaxi-<worker number>-00000000$i.csv') WITH DELIMITER = ',', SKIP = '1';"; done


создаем индексы    
CREATE INDEX taxi_trips_unique_key ON taxi_trips (unique_key);   

CREATE INDEX taxi_trips_payment_type ON taxi_trips (payment_type);    
 
 делаем запрос    
 
select payment_type,count(*) from taxi_trips group by payment_type;   

на этом запросе cockroach снова умер и больше не поднялся :   


```
 kubectl get all
NAME                                   READY   STATUS             RESTARTS   AGE
pod/cockroach-cockroachdb-0            0/1     Running            216        23h
pod/cockroach-cockroachdb-1            0/1     CrashLoopBackOff   221        23h
pod/cockroach-cockroachdb-2            0/1     CrashLoopBackOff   218        23h
pod/cockroach-cockroachdb-init-qmdsh   0/1     Completed          0          23h

NAME                                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)              AGE
service/cockroach-cockroachdb          ClusterIP   None          <none>        26257/TCP,8080/TCP   23h
service/cockroach-cockroachdb-public   ClusterIP   10.32.9.169   <none>        26257/TCP,8080/TCP   23h
service/kubernetes                     ClusterIP   10.32.0.1     <none>        443/TCP              25h

NAME                                     READY   AGE
statefulset.apps/cockroach-cockroachdb   0/3     23h

NAME                                   COMPLETIONS   DURATION   AGE
job.batch/cockroach-cockroachdb-init   1/1           29s        23h


```
за пол дня две сотни CrashLoopBackOff и так и не заработал.    

пошел снова убивать кластер ...    

**Учитывая что cockroach не выдерживает большие объемы при данной конфигурации железа, решено потестировать на файле в 1 гб.  Большего объема гугл просто не дает сохранить. Т.к. у него ограничения по выгрузке данных из больших таблиц установлены в 1гб.**    

 
 создаем новый :    

gcloud beta container --project "tensile-analyst-305614" clusters create "testcluster5" --zone "us-central1-c" --no-enable-basic-auth --cluster-version "1.17.17-gke.1101" --release-channel "None" --machine-type "e2-medium" --image-type "COS" --disk-type "pd-standard" --disk-size "150" --metadata disable-legacy-endpoints=true --scopes "https://www.googleapis.com/auth/devstorage.read_only","https://www.googleapis.com/auth/logging.write","https://www.googleapis.com/auth/monitoring","https://www.googleapis.com/auth/servicecontrol","https://www.googleapis.com/auth/service.management.readonly","https://www.googleapis.com/auth/trace.append" --num-nodes "3" --enable-stackdriver-kubernetes --enable-ip-alias --network "projects/tensile-analyst-305614/global/networks/default" --subnetwork "projects/tensile-analyst-305614/regions/us-central1/subnetworks/default" --default-max-pods-per-node "110" --no-enable-master-authorized-networks --addons HorizontalPodAutoscaling,HttpLoadBalancing --enable-autoupgrade --enable-autorepair --max-surge-upgrade 1 --max-unavailable-upgrade 0 --node-locations "us-central1-c"

выгружаем данные :    

SELECT * FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` LIMIT 3000000  

для постгреса   
 https://drive.google.com/file/d/1MpnPTG-6Z9MGaI9QsrCu59DzAPUUMqql/view?usp=sharing   
 
 
 и для  cockroach   
 gs://cikagotaxi/taxitest/3mfile.csv   
  
  gcloud init  
  
gcloud container clusters describe testcluster5 \  
    --zone=us-central1-c \  
     --format="value(endpoint)"  
  
  35.225.123.35  
     
gcloud container clusters describe testcluster5 \  
    --zone=us-central1-c \  
    --format="value(masterAuth.clusterCaCertificate)"    
    
 
**./kubeconfig.yaml**   
```
apiVersion: v1
kind: Config
clusters:
- name: testcluster5
  cluster:
    server: https://35.225.123.35
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURLekNDQWhPZ0F3SUJBZ0lSQVBmZXh1dVhBdmJaaE9RaFpGTXR1UGt3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa09USTNaalkwWXpBdE1tUm1ZeTAwTXpSa0xXSTFNR0V0WXpRMU56RTFZVGRpWmpJMQpNQjRYRFRJeE1ETXhNekV3TXpFeE1sb1hEVEkyTURNeE1qRXhNekV4TWxvd0x6RXRNQ3NHQTFVRUF4TWtPVEkzClpqWTBZekF0TW1SbVl5MDBNelJrTFdJMU1HRXRZelExTnpFMVlUZGlaakkxTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBeXdtb25sNSs4QWxVUlFDdlgyUndVSXV1RGEzamZ6d1BwNDd4Vnc4WQpjZW9OMlV3Rm5nOU1HcUp4SEZMVnJoVm96cW1UWk5qeHN3L0tZQlNvenYyVGhQbFJVTDdaL1R4Z3Y4NDFvTVpRCmFSWlhEQU0yNlBEODVkQk9QRnRyTzhnOWdmRGwrTy8wN1R1eWVvWlRZcjNOVFpWTCtKK0F6VTJYS2piOFJpVk8KMXRmOVdqWWs3TFRmdzMzMmcyakovK25IME1FaWpiTlh6dVZ4OFRoL2RZbzhGKzVpbU1zajRpUENSWERMT3JqSQpXRzdJZmR1cUlRVzV4Y1JObG01WkZqYW1GQ29RT3NiWHNUS3EvZzZsc2tyK0VHbkcxK05nWDFCMU1yTnZvNmZyCitidVRncS9DVU44SW5qaS9mOTJVdFQ3ZVhPekQyeGV2aHk4Y3dMa0xqQWVpWFFJREFRQUJvMEl3UURBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVXdiSU16dmZURXFVTwpka0dyc2hVTlFucVhFVVF3RFFZSktvWklodmNOQVFFTEJRQURnZ0VCQURQclhNSCtRYnpjVHM5OEdBTEVzQVV0CmxtUGU1ZWJxVlUrdUpRQXpwZmZsWThab0dnTlhVNkF0ZlJRTXFwNXhFZVZ5M3lNOElNd3JiWFRFbzlPV2xhTjYKRU5qOURrRnl6NmRRcEw0ZzhKNVcrZUdRcS9ISE5NQmZvTFEvajhqTDlTbjR0b2VyakUxTzNiZzgrM3RJY1ZSRwpocG9sUVNtR2c4M0JnaTVSRkx5NlQwK2tvaVFkeTFNUjV2SHRmcUtaUEF4cWNNNStpNkllZ2Z6M3lzbSthZkRqCmRPdUZrTGpRemdxK2RMVDB5VzdCMDZvSTY1STFJbGwwY2RGM2swU2hHN2xFa0l4Ti81Ymd3OEJySnFSSHFqZGkKWVF0QWw1VEl1VFBZSjJxTkpNS3Y2OHNldE1nc1ZacTROdC9qUG5jWWNDQklDSnlOSzlMT3FEY3RuUU9RWHJzPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
users:
- name: ci-cd-pipeline-gsa
  user:
    auth-provider:
      name: gcp
contexts:
- context:
    cluster: testcluster5
    user: ci-cd-pipeline-gsa
  name: testcluster5-ci-cd
current-context: testcluster5-ci-cd  
```

export KUBECONFIG=/tmp/kubeconfig.yaml   

gcloud iam service-accounts keys create gsa-key.json \   
    --iam-account=540654827891-compute@developer.gserviceaccount.com    

export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gsa-key.json   

kubectl run cockroachdb -it --image=cockroachdb/cockroach:v20.2.4 --rm --restart=Never -- sql --insecure --host=cockroach-cockroachdb-public  

заливаем гиг данных. (надеюсь не умрет)     

```
import into taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) CSV DATA ('gs://cikagotaxi/taxitest/3mfile.csv') WITH DELIMITER = ',', SKIP = '1';
        job_id       |  status   | fraction_completed |  rows   | index_entries |   bytes
---------------------+-----------+--------------------+---------+---------------+-------------
  641795686686687233 | succeeded |                  1 | 3000000 |             0 | 1206617501
(1 row)

Time: 87.188s total (execution 87.186s / network 0.002s)

CREATE INDEX taxi_trips_payment_type ON taxi_trips (payment_type);

CREATE INDEX

Time: 23.524s total (execution 0.037s / network 23.487s)


select payment_type,count(*) from taxi_trips group by payment_type;
  payment_type |  count
---------------+----------
  Cash         | 1760048
  Credit Card  | 1180538
  Dispute      |    1331
  No Charge    |   10052
  Prepaid      |      12
  Mobile       |    6539
  Pcard        |     713
  Prcard       |   23175
  Split        |     138
  Unknown      |   17438
  Way2ride     |      16
(11 rows)

Time: 1.357s total (execution 1.357s / network 0.001s)

```

= ставим кластер на постгрисе с отдельной виртуалки чтоб не путаться в конфигах =   

gcloud init  

создать в той же зоне гугл не дал. написал что то типа - не хватает процессоров.  
 пришлось выбирать другую зону :   
 

gcloud beta container --project "tensile-analyst-305614" clusters create "testcluster7" --zone "europe-west4-c" --no-enable-basic-auth --cluster-version "1.17.17-gke.1100" --release-channel "None" --machine-type "e2-medium" --image-type "COS" --disk-type "pd-standard" --disk-size "100" --metadata disable-legacy-endpoints=true --scopes "https://www.googleapis.com/auth/devstorage.read_only","https://www.googleapis.com/auth/logging.write","https://www.googleapis.com/auth/monitoring","https://www.googleapis.com/auth/servicecontrol","https://www.googleapis.com/auth/service.management.readonly","https://www.googleapis.com/auth/trace.append" --num-nodes "3" --enable-stackdriver-kubernetes --enable-ip-alias --network "projects/tensile-analyst-305614/global/networks/default" --subnetwork "projects/tensile-analyst-305614/regions/europe-west4/subnetworks/default" --default-max-pods-per-node "110" --no-enable-master-authorized-networks --addons HorizontalPodAutoscaling,HttpLoadBalancing --enable-autoupgrade --enable-autorepair --max-surge-upgrade 1 --max-unavailable-upgrade 0 --node-locations "europe-west4-c"   

gcloud container clusters describe testcluster7 \  
    --zone=europe-west4-c \  
     --format="value(endpoint)"  
      
     35.204.15.100  
     
gcloud container clusters describe testcluster7 \  
    --zone=europe-west4-c \  
    --format="value(masterAuth.clusterCaCertificate)"  
    
**./kubeconfig.yaml**   
    
```    
apiVersion: v1
kind: Config
clusters:
- name: testcluster7
  cluster:
    server: https://35.204.15.100
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURLekNDQWhPZ0F3SUJBZ0lSQUlmMGkvM1NQdHZTYjY3bndEMWYvV1l3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa1ltRTBPV013TmpRdE1UUXpNeTAwWW1Zd0xXSmlaakl0WkdZd01UaG1OelJtTWpFeApNQjRYRFRJeE1ETXhOakl4TURJMU4xb1hEVEkyTURNeE5USXlNREkxTjFvd0x6RXRNQ3NHQTFVRUF4TWtZbUUwCk9XTXdOalF0TVRRek15MDBZbVl3TFdKaVpqSXRaR1l3TVRobU56Um1NakV4TUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBbGhCRnkybWJ1dklCb0dUOVpuMUdxeWNJRjc5TEo4NnNZcm00bkg1WgpHK2hnQ0kzRkMwTnRoVlFsa01SaXdxTlZQWDF1eElJNWQ1MXdFYXFoaDY3UEo3NVVkYWpxUVQvYWV6SHFQeGZECjRqSms1YVJDTEZjVVFjN1Z4bndJSC9xaHdjV0h0M0xPL1VTVW1kL0FxRlRzODE1VVZ3Ky9sYTBYZ2RhUUhNeXoKNUtYNjBjWG1KL2NuUW5xY1BZeVdzQkp4bDRZOHRIUEdWQUVzYUFYWnRzOFZFam00V09iQ0tKMG5may9vd3FwdgpVQmhodjIzWjdra2FGWWFLNU1nTGNBZmh1d1RvSGNYMERBTkl1VXJCR0U5SVNnbjZaakhKcy9HZVZSNlh2ZE5OCnNrd3JSY1dUYTNtdnFCdzZFWVpCcTNjbzBmMDR4bk1haWdwOWFwM0taQTFZZndJREFRQUJvMEl3UURBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVUs0VXliV1RTUFRYWApOSzJIRUtZekZtTXBLTVl3RFFZSktvWklodmNOQVFFTEJRQURnZ0VCQUF4cC9CMjF3Szl2ajNtWXpJQnl3QTl0CmRtR1haakVXajl2eXJEOXhQcVdKQS9rQ0xTYnAxMGFCNUtaaU90U3VPVzhWSVpqQjVLNVIzK2pJSDJMR2ZOVFoKRjQ2MmErSCtJelAvc0hlbkFOdHJFeU1pM0hNZGNiTGRTWWUvK1doMGlmT0dVOFp3OEtUb1JlWjlFMm0wbUs2QQpwSWNIQWQyVGZRbzNQajd2WVhnRmhRM20vOGxOVHZjaDNML1JrRkRmVzNyTGpTbThENXdrTitXZFB4c1U4MGlPCm1RL2tBMEs5bFpJRmExNWlNT2RwZkRwa1grMnMvd3VIajAya3dITkZIcGNianR4d2RmVndZbE5SakovZkJ6QmkKTnpvWlU0UytOekRhVE1QejdkblpKRDFLWHBLWjdMQkhRa1R5cldMSkVHT084N0lXc1FLVTM2MG5aT2JLbUtJPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
users:
- name: ci-cd-pipeline-gsa
  user:
    auth-provider:
      name: gcp
contexts:
- context:
    cluster: testcluster4
    user: ci-cd-pipeline-gsa
  name: testcluster7-ci-cd
current-context: testcluster7-ci-cd  
```    

export KUBECONFIG=/tmp/kubeconfig.yaml    

gcloud container clusters get-credentials testcluster7 \    
    --zone=europe-west4-c   
    
gcloud iam service-accounts keys create gsa-key.json \   
    --iam-account=540654827891-compute@developer.gserviceaccount.com    

export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gsa-key.json   

Ставим постгрес кластер 

 helm repo add bitnami https://charts.bitnami.com/bitnami     

c помощью helm устанавливаем postgresql      

  helm install pgsql-ha bitnami/postgresql-ha  

```
  helm install pgsql-ha bitnami/postgresql-ha
NAME: pgsql-ha
LAST DEPLOYED: Tue Mar 16 22:32:52 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **

PostgreSQL can be accessed through Pgpool via port 5432 on the following DNS name from within your cluster:

    pgsql-ha-postgresql-ha-pgpool.default.svc.cluster.local

Pgpool acts as a load balancer for PostgreSQL and forward read/write connections to the primary node while read-only connections are forwarded to standby nodes.

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default pgsql-ha-postgresql-ha-postgresql -o jsonpath="{.data.postgresql-password}" | base64 --decode)

To get the password for "repmgr" run:

    export REPMGR_PASSWORD=$(kubectl get secret --namespace default pgsql-ha-postgresql-ha-postgresql -o jsonpath="{.data.repmgr-password}" | base64 --decode)

To connect to your database run the following command:

    kubectl run pgsql-ha-postgresql-ha-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql-repmgr:11.11.0-debian-10-r25 --env="PGPASSWORD=$POSTGRES_PASSWORD"  \
        --command -- psql -h pgsql-ha-postgresql-ha-pgpool -p 5432 -U postgres -d postgres

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/pgsql-ha-postgresql-ha-pgpool 5432:5432 &
    psql -h 127.0.0.1 -p 5432 -U postgres -d postgres
```

 export POSTGRES_PASSWORD=$(kubectl get secret --namespace default pgsql-ha-postgresql-ha-postgresql -o jsonpath="{.data.postgresql-password}" | base64 --decode)  

 echo $POSTGRES_PASSWORD   
HNNxSyKLpp  

 для того чтоб появился psql ( sudo apt-get -y install postgresql )   
 
kubectl port-forward --namespace default svc/pgsql-ha-postgresql-ha-pgpool 5432:5432 & psql -h 127.0.0.1 -p 5432 -U postgres -d postgres   
    
    
```

create table taxi_trips(
unique_key  varchar ,
taxi_id  varchar ,
trip_start_timestamp  varchar ,
trip_end_timestamp  varchar ,
trip_seconds  varchar ,
trip_miles  varchar ,
pickup_census_tract  varchar ,
dropoff_census_tract  varchar ,
pickup_community_area  varchar ,
dropoff_community_area  varchar ,
fare  varchar ,
tips  varchar ,
tolls  varchar ,
extras  varchar ,
trip_total  varchar ,
payment_type  varchar ,
company  varchar ,
pickup_latitude  varchar ,
pickup_longitude  varchar ,
pickup_location  varchar ,
dropoff_latitude  varchar ,
dropoff_longitude  varchar ,
dropoff_location  varchar 
);
\dt
           List of relations
 Schema |    Name    | Type  |  Owner   
--------+------------+-------+----------
 public | taxi_trips | table | postgres
(1 row)
\q
```
заливаем данные заранее скопированные на виртуалку :   
```
 ls -lh /home/alex/
total 1.1G
-rw-rw-r-- 1 alex alex 1.1G Mar 16 15:36 bq-results-20210313-143730-ge4w66qwbm97.csv
```
команда из консоли :   

cat /home/alex/bq-results-20210313-143730-ge4w66qwbm97.csv | psql -h 127.0.0.1 -p 5432 -U postgres -d postgres    -c "COPY public.taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) from STDIN DELIMITER ','  CSV HEADER;"   

HNNxSyKLpp   

```
cat /home/alex/bq-results-20210313-143730-ge4w66qwbm97.csv | psql -h 127.0.0.1 -p 5432 -U postgres -d postgres    -c "COPY public.taxi_trips (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) from STDIN DELIMITER ','  CSV HEADER;" 
Handling connection for 5432
Password for user postgres: 
Handling connection for 5432
Handling connection for 5432
Handling connection for 5432
COPY 3000000
```

создадим индекс и запрос   

```
 select payment_type,count(*) from taxi_trips group by payment_type;
 payment_type |  count  
--------------+---------
 Cash         | 1760048
 Credit Card  | 1180538
 Dispute      |    1331
 Mobile       |    6539
 No Charge    |   10052
 Pcard        |     713
 Prcard       |   23175
 Prepaid      |      12
 Split        |     138
 Unknown      |   17438
 Way2ride     |      16
(11 rows)

explain analyze select payment_type,count(*) from taxi_trips group by payment_type;
                                                                       QUERY PLAN                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate  (cost=169229.26..169231.54 rows=9 width=15) (actual time=2435.223..2437.160 rows=11 loops=1)
   Group Key: payment_type
   ->  Gather Merge  (cost=169229.26..169231.36 rows=18 width=15) (actual time=2435.204..2437.118 rows=32 loops=1)
         Workers Planned: 2
         Workers Launched: 2
         ->  Sort  (cost=168229.23..168229.26 rows=9 width=15) (actual time=2421.035..2421.038 rows=11 loops=3)
               Sort Key: payment_type
               Sort Method: quicksort  Memory: 25kB
               Worker 0:  Sort Method: quicksort  Memory: 25kB
               Worker 1:  Sort Method: quicksort  Memory: 25kB
               ->  Partial HashAggregate  (cost=168229.00..168229.09 rows=9 width=15) (actual time=2420.957..2420.963 rows=11 loops=3)
                     Group Key: payment_type
                     ->  Parallel Seq Scan on taxi_trips  (cost=0.00..161979.00 rows=1250000 width=7) (actual time=0.056..820.062 rows=1000000 loops=3)
 Planning Time: 0.136 ms
 Execution Time: 2437.250 ms
(15 rows)


```
смотрим живы ли поды   
Постгрес :   
```
 kubectl get all
NAME                                                READY   STATUS    RESTARTS   AGE
pod/pgsql-ha-postgresql-ha-pgpool-556b4676f-gntml   1/1     Running   0          32m
pod/pgsql-ha-postgresql-ha-postgresql-0             1/1     Running   0          32m
pod/pgsql-ha-postgresql-ha-postgresql-1             1/1     Running   0          32m
```

cockroach   

```
 kubectl get all
NAME                                   READY   STATUS      RESTARTS   AGE
pod/cockroach-cockroachdb-0            1/1     Running     0          86m
pod/cockroach-cockroachdb-1            1/1     Running     0          86m
pod/cockroach-cockroachdb-2            1/1     Running     1          86m
pod/cockroach-cockroachdb-init-qjhvl   0/1     Completed   0          86m
```
**cockroach успел один раз упасть** 

## Вывод : ##
  cockroach - вероятно требователен к железу. И при тесте на больших объемах падает. При попытке просто удвоить данные он опять отвалился.   
  Кластер на postgresql чуть меньшую скорость, но более высокую стабильность и предсказуемость.  
  Так же язык cockroach немного отличается от psql   
  в cockroach - не работают анонимные процедуры и свой синтаксис команд.     
  
  
  
 
